{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD-TSIA211 : TP2 - BREAST CANCER DATA ANALYSIS\n",
    "\n",
    "## Remi Jaylet & Romain Louvet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_breastcancer(filename):\n",
    "    \"\"\"\n",
    "    Cette fonction lit le fichier filename, par exemple\n",
    "    filename = 'wdbc_M1_B0.data'\n",
    "    Elle retourne \n",
    "    X : une matrice de caracteristiques\n",
    "    y : un vecteur des classes tel que si y[i] = 1, la tumeur est maligne\n",
    "        et si y[i] = -1, la tumeur est benigne\n",
    "\n",
    "    Pour plus d'infos sur la base de donnees,\n",
    "    https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Prognostic%29\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "\n",
    "    # la colonne 0 ne nous interesse pas ici\n",
    "    y = data[:, 1] * 2 - 1\n",
    "    X = data[:, 2:]\n",
    "\n",
    "    # Standardisation de la matrice\n",
    "    X = X - np.mean(X, axis=0)\n",
    "    X = X / np.std(X, axis=0)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_breastcancer(\"wdbcM1B0.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Sub-gradient method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Question 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "According to the the two inequalties in the text, we have : $$ \\forall i, \\xi_{i} \\geq max(0,1-y_{i}(x_{i}^Tv+a)) $$\n",
    "\n",
    "As the left term of two expressions are the same, the difference is in the reformulation of xi_i. However it is equivalent to minimize $$ \\forall i, \\xi_{i} \\quad \\textrm{and} \\quad max(0,1-y_{i}(x_{i}^Tv+a)) $$\n",
    "\n",
    "Thus, the two expressions are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Question 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEICAYAAABLdt/UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAGw1JREFUeJzt3Xl4VPXZxvHvk4UtCChgBIKibC6A2ARkU0Gx2hYFd617axEV1Fpba5e3tnWrbX37CriDu6YuqBCxamtSDbKFRQSxrQsggisgBlfI8/4xMyUiS5g5kzNz5v5c11xkmXPO87sCNycnd86YuyMiItGRF/YAIiISLAW7iEjEKNhFRCJGwS4iEjEKdhGRiFGwi4hEjIJdZBvM7FYz+3Ua9nuVmd0f9H5FEgrCHkBka8xsGVAMbKr34R7uvipNxzsHOM/dhyQ+5u5j0nEskXRTsEsmO8bd/x72ECLZRpdiJKuY2VAzW7nFx5aZ2fD421eZ2cNmdq+ZfWJmS8ysrN5zO5vZFDP7wMw+MrMJZrYfcCsw0MxqzWxd/Ll3m9nV9bb9kZm9bmZrzGyqmXWs9zk3szFm9h8zW2tmE83MtrOUJtuaUSRVCnaJomOBcqANMBWYAGBm+UAFsBzoAnQCyt19KTAGmOnuLd29zZY7NLPDgeuAk4EO8X2Ub/G0EUA/4MD4847a2RlFgqBgl0z2hJmtiz+e2Intqt19urtvAu4jFrQA/YGOwE/dfYO7f+7u1Q3c5+nAZHef7+5fAFcSO8PvUu8517v7OndfAVQCfZOYUSRlCnbJZKPcvU38MWontnu33tufAs3MrADoDCx3941JzNKR2Fk6AO5eC3xE7Kx/W8dtmcSMIilTsEu22QC0SLwTv7zSvoHbvg3suY0A3dFtTlcBe9U7bhHQFningccWaTQKdsk2/yZ2dvs9MysEfgU0beC2c4DVwPVmVmRmzcxscPxz7wElZtZkG9s+CJxrZn3NrClwLTDb3ZclvRKRNFGwS1Zx94+BC4E7iZ0tbwBWbnejzdtuAo4BugEr4tudEv/088AS4F0z+3Ar2/4D+DXwGLH/HLoCp6ayFpF0Mb3QhohItOiMXUQkYhTsIiIRo2AXEYkYBbuISMSE8gsR7dq18y5duiS17YYNGygqKgp2oJBoLZkpKmuJyjpAa0mYN2/eh+6+w9/bCCXYu3TpQk1NTVLbVlVVMXTo0GAHConWkpmispaorAO0lgQzW77jZ+lSjIhI5CjYRUQiRsEuIhIxCnYRkYhRsIuIRExgwW5m+Wa2wMwqgtqniIjsvCDP2C8Blga4PxERSUIgwW5mJcD3iN1KNW1qlq3h6be+QnekFBHZtkBu22tmjxJ7od9dgMvdfcRWnjMaGA1QXFxcWl6+5esA79i9r37B8ys2Ulaczw97N6V5wfZeBD7z1dbW0rLl9l49LXtoLZknKusArSVh2LBh89y9bIdPdPeUHsRemf3m+NtDgYodbVNaWurJqKur859Nftb3ufIpH/anSv/3u+uT2k+mqKysDHuEwGgtmScq63DXWhKAGm9ALgdxKWYwcKyZLQPKgcPN7P4A9vsNZsZ39i7kgfMOZv1nXzFy4gymvbwqHYcSEclaKQe7u1/p7iXu3oXYS4U97+5npDzZdgzYpy1PXXwI+3VoxbiHFvC7aa/y1aa6dB5SRCRrZG2PvbhVMx760QDOGdSFyTPe4vt3zOL99Z+HPZaISOgCDXZ3r/Kt/OA0XZoU5HHVsQfwf6f2ZfE76/nuTdXMfvOjxjq8iEhGytoz9vpG9u3Ek2MH06pZAd+/czZ3vPCmKpEikrMiEewAPYp34cmxgzlyv2Kumb6Uix6cT+0XG8MeS0Sk0UUm2AF2aVbILWd8iyu/sy9/W/wuIydU8/r7n4Q9lohIo4pUsEOsEnn+YV154LwBfPzZVxw7YQYVi1SJFJHcEblgTxjYtS0V42KVyLEPqhIpIrkjssEOsEdrVSJFJPdEOtjhm5XI742vZs5ba8IeS0QkbSIf7Akj+3biiYsGs0vTAk67YxZ3vqhKpIhEU84EO0DPPTZXIq9+ailjH1ygSqSIRE5OBTt8vRL59OLVqkSKSOTkXLDDNyuRIyfM4KlFq8MeS0QkEDkZ7AmJSuS+HVpx0YPz+X2FKpEikv1yOtjh65XISdVvcfods1WJFJGslvPBDl+vRL7yzseqRIpIVlOw16NKpIhEgYJ9C4lK5PD9do9VIh9SJVJEsouCfSt2aVbIrWeUxiqRr6xm1MQZqkSKSNZQsG9DohJ5/3kHs+7TLxk5YQbTX1ElUkQyn4J9BwZ1bUfFuEPouccuXPjAfK5WJVJEMpyCvQH2aN2M8tEDOWdQF+5MVCI/USVSRDKTgr2BvlGJvKmauctUiRSRzKNg30mJSmTLpgWcdvssJlW/pUqkiGQUBXsSEpXII/bbnd9XvMq4hxawQZVIEckQCvYktYpXIn/+nX2Z/spqRk6cwevv14Y9loiIgj0VZsaYw7py/w8PZu2GLxk5oVqVSBEJnYI9AIO6taPi4iH0iFcir3nqVTaqEikiIVGwB6RD6+b8dfRAzh64F3e8+Bbfv1OVSBEJh4I9QE0K8vjtyF785ZS+vLLyY0aoEikiIVCwp8Gogzrx+EWDaNEkn9Nun8VkVSJFpBEp2NNk3z1aMXXcEA7fd3d+p0qkiDQiBXsatWpWyG1nlnLF0bFK5ChVIkWkEaQc7GbWzMzmmNnLZrbEzH4bxGBRYWZcMDRWiVwTr0Q+rUqkiKRREGfsXwCHu/uBQF/gaDMbEMB+I6V+JfKCB+Zz7fSlbKrTdXcRCV7Kwe4xiesLhfGHEmsrEpXIswbuxe0vvMkNcz9XJVJEAmdBtDXMLB+YB3QDJrr7FVt5zmhgNEBxcXFpeXl5Useqra2lZcuWKUybGV5atZG7Fn9OUWEeF/ZtSo9d88MeKSVR+bpAdNYSlXWA1pIwbNiwee5etsMnuntgD6ANUAn02t7zSktLPVmVlZVJb5tp7p36Dz/shue965VP+aQX3/S6urqwR0palL4uUVlLVNbhrrUkADXegCwOtBXj7uuAKuDoIPcbVZ13yWPquCEMUyVSRAIURCumvZm1ib/dHBgOvJbqfnNFq2aF3HZGKT87uqcqkSISiCDO2DsAlWa2CJgLPOfuFQHsN2fk5RkXDu3GfapEikgAgmjFLHL3g9y9j7v3cvffBTFYLhocr0R2L95cidRdIkVkZ+k3TzNMh9bN+ev5AzhzQKwSebruEikiO0nBnoGaFuTz+1G9+N9TDuTllesYcVM1NbpLpIg0kII9gx13UAmPXziYFk3yOVV3iRSRBlKwZ7j9OrTiybGbK5EXly9UJVJEtkvBngVaN99ciXxq0SpGTZzBGx+oEikiW6dgzxLfrETOUCVSRLZKwZ5lEpXIbru3VCVSRLZKwZ6FtqxEnjFpNh988kXYY4lIhlCwZ6n6lciFb69jxPgXmbdclUgRUbBnvUQlsnlhPqfcNou7ZqgSKZLrFOwRUL8S+dtpr3KJKpEiOU3BHhGJSuRPj+pJxaJVHHfzDN5UJVIkJynYIyQvz7hoWKwS+WHtlxw7YQZ/W6xKpEiuUbBH0OBu7agYF6tEjrl/PtepEimSUxTsEdWxzeZK5G2qRIrkFAV7hCUqkTeerEqkSC5RsOeA478Vq0Q2i1ci71YlUiTSFOw5Yr8OrZg6dghDe+7OVfFK5KdfqhIpEkUK9hzSunkht5+5uRI5aqIqkSJRpGDPMYlK5L0/qF+JfDfssUQkQAr2HDWke6wS2XX3loy5fx7XPa1KpEhUKNhzWMc2zXn4/AGcMWBPbvvnm5w5aY4qkSIRoGDPcU0L8rl6VG9uPPlAFry9Nl6JXBv2WCKSAgW7ALFK5JQLYpXIU2+fyT0vLVMlUiRLKdjlv/bvGKtEHtajPb+ZuoRL/6pKpEg2UrDL18QqkWX89KieTHt5FcdNfEmVSJEso2CXb6hfifyg9gtGqhIpklUU7LJNQ7q3Y9q4IezTvogx98/j+qdfUyVSJAso2GW7OrVpzsNjBnL6wXty6z/f4MxJc/iwVpVIkUymYJcdalqQzzXH9ebPJx3I/BVrGXFTtSqRIhks5WA3s85mVmlmS81siZldEsRgknlOKI3dJbJJQZ4qkSIZLIgz9o3AT9x9P2AAcJGZ7R/AfiUD7d+xFdPGDuHQ7rFK5I9ViRTJOCkHu7uvdvf58bc/AZYCnVLdr2Su1i0KueOsMi7/dg+ejFci392gH6qKZAoL8ltpM+sCvAD0cvf1W3xuNDAaoLi4uLS8vDypY9TW1tKyZcvUBs0QUVjL4g83cevLn7OxzvlRn2aUFheEPVLKovB1geisA7SWhGHDhs1z97IdPtHdA3kALYF5wPE7em5paaknq7KyMultM01U1rJy7ac+9NrpvtcVFX7d9KX+1cZNYY+Ukqh8XaKyDnetJQGo8QbkcSCtGDMrBB4DHnD3KUHsU7JHpzbN+cXBzfh+vBJ51mRVIkXCFEQrxoBJwFJ3vzH1kSQbFeYZ1x7Xmz+ddCDzlqsSKRKmIM7YBwNnAoeb2cL447sB7Fey0ImlJUy5cJAqkSIhSvknXe5eDVgAs0hEHNCxNdPGDuGyhxfym6lLWLBiLdce35sWTbL/B6si2UC/eSppkahE/uTIzZXItz7cEPZYIjlBwS5pk5dnjDuiO/ec25/3P/mcY8dX88wS3SVSJN0U7JJ2h/ZoT8XFh7BP+yLOv093iRRJNwW7NIrEXSJViRRJPwW7NJqmBfnfqETOX6FKpEjQFOzS6OpXIk+5bSb3zlQlUiRICnYJRaISeWj39vzPk0u47OGXdZdIkYAo2CU09SuRTyx8h+NvViVSJAgKdglV/Urke+tjlchnVYkUSYmCXTLCoT3aM23cEPZuX8To++bxh7+pEimSLAW7ZIySXVvwSLwSeUuVKpEiyVKwS0ZJVCL/eGIf5i1fyzHjq1mgSqTITlGwS0Y6qawzUy4cREG+cfJtM7lvpiqRIg2lYJeMdUDH1lSMPYRDurfn1/FK5Gdfbgp7LJGMp2CXjNa6RSF31qtEHnfzDJapEimyXQp2yXiJSuTd5/bn3fWfc8yEap579b2wxxLJWAp2yRqH9WhPxbgh7N2uiB/dW8MNf3uNTXW67i6yJQW7ZJWSXVvw8PkDOa3/ntxc9QZnTZ7NR6pEinyNgl2yTrPCfK47vjc3nNiHmmVrGaFKpMjXKNgla51c1pnHLqhXiZy1XJVIERTskuV6dYpVIod0a8evn1jMT1SJFFGwS/Zr3aKQSWf347Ije/C4KpEiCnaJhrw842JVIkUABbtEzGE92jNt7BC6tI1VIv/4jCqRknsU7BI5nXeL3SXytP6dmVj5BmdPnqNKpOQUBbtEUqwS2YcbTuzDnGVrOGZ8NQvfXhf2WCKNQsEukXZyWWemXDCIvDzjpFtf4n5VIiUHKNgl8np1ak3FuCEM6daOXz2xmJ88okqkRJuCXXJCmxZNmHR2P348vAePL4hVIpd/pEqkRJOCXXJGXp5xyfDu3HVOP95d/zkjxlfzd1UiJYIU7JJzhvbc/b+VyPPureFPz/xLlUiJlECC3cwmm9n7ZrY4iP2JpFuiEnlqv85MqHydc+6aw5oNX4Y9lkgggjpjvxs4OqB9iTSKZoX5XH9CH244oQ+z31rDiJteVCVSIiGQYHf3F4A1QexLpLGd3G9zJfLkW2fy/IqvVImUrGZB/QU2sy5Ahbv32sbnRwOjAYqLi0vLy8uTOk5tbS0tW7ZMcsrMorVkltovndsXfcGiDzcxuGMBZx3QhKb5FvZYSYvC1yRBa4kZNmzYPHcv29HzGi3Y6ysrK/OampqkjlNVVcXQoUOT2jbTaC2Zp67OuWzyczz5xlfsu0crbj3jW+zVtijssZISla8JaC0JZtagYFcrRqSevDxjVLcm3HVOP1at+4wR46v5x1JVIiW7KNhFtmJoz92pGBerRP7wHlUiJbsEVXd8CJgJ9DSzlWb2wyD2KxImVSIlWwXVijnN3Tu4e6G7l7j7pCD2KxI2VSIlG+lSjEgDbFmJ1F0iJZMp2EUaKHGXyEHd2vKrJxZz+SOLdJdIyUgKdpGd0KZFEyaf3Y9Lh3dnyoKVHH/LS7pLpGQcBbvITsrLMy4d3kOVSMlYCnaRJCUqkXu1baFKpGQUBbtICjrv1oJHxwzilDJVIiVzKNhFUtSsMJ8/nNiHP5zQm9lvxV44+2VVIiVECnaRgJzSb08eGzMIMzjp1pk8MFuVSAmHgl0kQL1LYpXIgV3b8svHY5XIz79SJVIal4JdJGBtWsRuInbJEfFK5M0vseKjT8MeS3KIgl0kDfLyjB8f2YPJ5/TjnXWfMWL8i6pESqNRsIuk0bB4JXLPeCXyz8+qEinpp2AXSbP6lcjxz6sSKemnYBdpBIlK5PXHqxIp6adgF2lEp/aPVSIhVol8cPYKVSIlcAp2kUZWvxL5i8df4aePqhIpwVKwi4Rg16ImTI5XIh+br0qkBEvBLhKS/EQl8uzNlcjnX1MlUlKnYBcJ2bB9Y5XIzru14Ad313CjKpGSIgW7SAbovFsLHrtgECeXlXBTvBK5VpVISZKCXSRDNCvM54YTD/xvJXLE+GoWrVQlUnaegl0kw5zaf08eHTMQgBNvmclDc1SJlJ2jYBfJQH1K2lAxbggDurblyimv8DNVImUnKNhFMtSuRbG7RF58RHcembeSE25RJVIaRsEuksHy84zLjoy9cPbbaz5lxPgXqXzt/bDHkgynYBfJArFK5CGU7NqCc++ey43P/VuVSNkmBbtIltizbQumXDiIk0pLuOkf/+Hcu+eqEilbpWAXySKxSmQfrju+N7Pe+EiVSNkqBbtIljEzTuu/J49esLkSWT5nRchTSSZRsItkqT4lbZg2bggH77MbP5/yCj979GVVIgUIKNjN7Ggz+5eZvW5mPw9inyKyY7sVNeHuc/tz8eHdeLgmVol8e40qkbku5WA3s3xgIvAdYH/gNDPbP9X9ikjD5OcZl327J5PPKYtXIqtVicxxBQHsoz/wuru/CWBm5cBI4NUA9i0iDXT4vsVUjDuEMffP4wf3zOXcgpUU/XNh2GMFYv3qVcyNyFo+69oh7ccIItg7AW/Xe38lcPCWTzKz0cBogOLiYqqqqpI6WG1tbdLbZhqtJTNl+1ou7eXcl1fAcdf8kd7vvRH2OLKFRy6/iqqSqrQeI4hgt6187Bu/OeHutwO3A5SVlfnQoUOTOlhVVRXJbptptJbMFIW1fPsI+OSGL/ls+FGsuf7PYY+TsoULF9C370FhjxGINu+uSPvfryCCfSXQud77JcCqAPYrIinI9zqa796WTqUHhD1Kyv7zyQeRWAfAf6o+SPsxgmjFzAW6m9neZtYEOBWYGsB+RSQFVlcH+flhjyEhSPmM3d03mtlY4BkgH5js7ktSnkxEUqJgz11BXIrB3acD04PYl4gEwzZtgoJA/olLltFvnopElG3apDP2HKVgF4kqXYrJWQp2kYjSGXvuUrCLRJTV1ekae45SsItElFoxuUvBLhJRuhSTuxTsIhGlumPuUrCLRJQuxeQuBbtIFNXVxf5UsOckBbtIFG3cGPtTl2JykoJdJIo2xV/7VGfsOUnBLhJFCvacpmAXiaLEpRgFe05SsItEUeKMXdfYc5KCXSSKdCkmpynYRaJIl2JymoJdJIp0KSanKdhFokiXYnKagl0kihTsOU3BLhJF+s3TnKZgF4kinbHnNAW7SBQp2HOagl0kilR3zGkKdpEoUt0xpynYRaJIl2JymoJdJIp0KSanKdhFokiXYnKagl0kinQpJqcp2EWiSMGe0xTsIlGk3zzNaQp2kSjSGXtOSynYzewkM1tiZnVmVhbUUCKSIgV7Tkv1jH0xcDzwQgCziEhQVHfMaSldgHP3pQBmFsw0O3L11fS7804oKmqc46VZvw0btJYMFIm1rF8f+1PBnpMa7ScrZjYaGA1QXFxMVVXVTu+jw8cfs0tJCRsi8gOhjbvuqrVkoEispX17PjvgAJatXo1/+GHY06SstrY2qczIRI2yFnff7gP4O7FLLls+RtZ7ThVQtqN9JR6lpaWerMrKyqS3zTRaS2aKylqisg53rSUBqPEGZOwOT0vcfXia/k8REZE0UN1RRCRiUq07HmdmK4GBwFNm9kwwY4mISLJSbcU8Djwe0CwiIhIAXYoREYkYBbuISMQo2EVEIkbBLiISMRbrvDfyQc0+AJYnuXk7IPt/lS5Ga8lMUVlLVNYBWkvCXu7efkdPCiXYU2FmNe4eiTtJai2ZKSprico6QGvZWboUIyISMQp2EZGIycZgvz3sAQKktWSmqKwlKusArWWnZN01dhER2b5sPGMXEZHtULCLiERMVga7mf3ezBaZ2UIze9bMOoY9U7LM7I9m9lp8PY+bWZuwZ0pWtr+4uZkdbWb/MrPXzeznYc+TLDObbGbvm9nisGdJlZl1NrNKM1sa/7t1SdgzJcvMmpnZHDN7Ob6W36btWNl4jd3MWrn7+vjbFwP7u/uYkMdKipl9G3je3Tea2R8A3P2KkMdKipntB9QBtwGXu3tNyCM1mJnlA/8GjgRWAnOB09z91VAHS4KZHQrUAve6e6+w50mFmXUAOrj7fDPbBZgHjMrSr4sBRe5ea2aFQDVwibvPCvpYWXnGngj1uCIg+/53inP3Z909/pLyzAJKwpwnFe6+1N3/FfYcSeoPvO7ub7r7l0A5MDLkmZLi7i8Aa8KeIwjuvtrd58ff/gRYCnQKd6rkxF/drjb+bmH8kZbsyspgBzCza8zsbeB04H/CnicgPwCeDnuIHNUJeLve+yvJ0gCJKjPrAhwEzA53kuSZWb6ZLQTeB55z97SsJWOD3cz+bmaLt/IYCeDuv3T3zsADwNhwp92+Ha0l/pxfAhuJrSdjNWQtWcq28rGs/U4wasysJfAYcOkW37FnFXff5O59iX1n3t/M0nKpLKVXUEqnnXgR7QeBp4DfpHGclOxoLWZ2NjACOMIz/IceEX5x85VA53rvlwCrQppF6olfj34MeMDdp4Q9TxDcfZ2ZVQFHA4H/kDtjz9i3x8y613v3WOC1sGZJlZkdDVwBHOvun4Y9Tw6bC3Q3s73NrAlwKjA15JlyXvwHjpOApe5+Y9jzpMLM2idab2bWHBhOmrIrW1sxjwE9iTUwlgNj3P2dcKdKjpm9DjQFPop/aFYWN3yOA8YD7YF1wEJ3PyrcqRrOzL4L/AXIBya7+zUhj5QUM3sIGErs9rDvAb9x90mhDpUkMxsCvAi8QuzfO8Av3H16eFMlx8z6APcQ+/uVBzzs7r9Ly7GyMdhFRGTbsvJSjIiIbJuCXUQkYhTsIiIRo2AXEYkYBbuISMQo2EVEIkbBLiISMf8Pn2glu3n+e3cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def h(z):\n",
    "    return np.maximum(np.zeros(z.shape),1-z)\n",
    "\n",
    "def d(z):\n",
    "    res = []\n",
    "    for i in range(len(z)):\n",
    "        if z[i] < 1 :\n",
    "            res.append(-1)\n",
    "        elif z[i] > 1 :\n",
    "            res.append(0)\n",
    "        else : \n",
    "            res.append(arange(0,1,0.01))\n",
    "    return res\n",
    "\n",
    "x=np.arange(-3,3,0.01)\n",
    "\n",
    "plt.plot(x,h(x))\n",
    "plt.plot(x,d(x), color = \"red\")\n",
    "plt.title(\"Function h\")\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For all z != 1, h is differentiable. Pour z = 1, we can see that all the slopes between -1 and 0 can fit. The expression of the subject is thus correct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "For the two seperable expressions, we take :\n",
    "\n",
    "$$ N(v)=\\frac{1}{2} \\sum_{i=1}^{m+1} n_i(v_i) \\quad \\textrm{and} \\quad H(v)=\\frac{1}{2} \\sum_{i=1}^{m+1} h_i(v_i) $$\n",
    "\n",
    "with $$ \\forall i \\in [1,n],  n_i(v_i)=v_iÂ² \\quad \\textrm{and} \\quad h_i(v_i)=max(0, 1 - v_i) $$\n",
    "\n",
    "N and H are well seperable.\n",
    "For the linear application, we have the following expression : $$ M(v) = y_{i}(x_{i}^Tv+a) $$\n",
    "\n",
    "\n",
    "Hence, $f(v,a) = N(v,a) + cH(M(v,a))$\n",
    "\n",
    "\n",
    "\n",
    "As N is differentiable, we have :  $\\partial N(v,a) = (v, 0)$\n",
    "As H is seperable, we have : $\\partial H(M(v,a)) = \\prod_i \\partial h(M_i(v,a)) = \\prod_i \\partial h(y_i(x_i^Tv+a))$\n",
    "\n",
    "We differentiate the function f is $\\partial f(v,a) = \\partial N(v,a) + cM^T \\partial H (M(v,a)).$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "c = 1\n",
    "M = np.dot(np.diag(y), np.concatenate([X, np.ones((569,1))], axis = 1))\n",
    "\n",
    "\n",
    "def N(va):\n",
    "    return (1/2) * np.sum(va[:-1]**2)\n",
    "\n",
    "def H(va):\n",
    "    return np.sum(h(np.dot(M,va)))\n",
    "\n",
    "def f(va):\n",
    "    return N(va) + c * H(va)\n",
    "\n",
    "def dev_N(va):\n",
    "    return np.concatenate([va[:-1], [0]])\n",
    "\n",
    "def dev_H(va):\n",
    "    return np.dot(np.transpose(M), (np.dot(M,va)>=1) - 1)\n",
    "\n",
    "def dev_f(va):\n",
    "    return dev_N(va) + c * dev_H(va)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sub_gradient(va0, N):\n",
    "    \"\"\"\n",
    "        implementation of the subgradient method explained i nthe subject\n",
    "    \"\"\"\n",
    "    sum_gamma = 0\n",
    "    sum_va = np.zeros(va0.shape)\n",
    "    for k in range(N):\n",
    "        gamma = 1/(k+1)\n",
    "        sum_gamma += gamma\n",
    "        sum_va += va0*gamma\n",
    "        va0 = va0-gamma*dev_f(va0)\n",
    "    return sum_va/sum_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial value of f : 569.0\n",
      "Final value of f : 16989.301940798585\n"
     ]
    }
   ],
   "source": [
    "va0 = np.zeros((31,))\n",
    "print(\"Initial value of f :\", f(va0))\n",
    "va1 = sub_gradient(va0, 10000)\n",
    "print(\"Final value of f :\",f(va1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Stochastic subgradient method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "$$ E(f_I(v,a)) = \\sum_i P(I = i) \\times f_i(v,a) = \\frac{1}{n}\\sum_i f_i(v,a) $$\n",
    "\n",
    "Hence, $$ E(f_I(v,a)) = \\frac{1}{2n} \\sum_j n\\,v_j^2 + \\frac{1}{n}\\sum_i c\\,n\\,max(0,1-y_i(x_i^Tv + a))$$ \n",
    "\n",
    "Thus, $$ E(f_I(v,a)) = \\frac{1}{2} \\sum_j v_j^2 + c\\sum_i max(0,1-y_i(x_i^Tv + a))= f(v,a)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\partial f_i(v,a) = \\partial N(v,a) + c\\, n\\, M_i^T\\partial H(M_i(v,a)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dev_H_i(va, i):\n",
    "    return ((np.dot(M[i,:],va)>=1)- 1) * M[i,:]\n",
    "\n",
    "def dev_f_i(va, i):\n",
    "    return dev_N(va) +  M.shape[0] * dev_H_i(va,i)\n",
    "\n",
    "def stochastic_gradient(va0, N):\n",
    "    \"\"\"\n",
    "    implementatio nof the stochastic gradient method\n",
    "    \"\"\"\n",
    "    n = M.shape[0]\n",
    "    sum_gamma = 0\n",
    "    sum_va = np.zeros(va0.shape)\n",
    "    for k in range(N):\n",
    "        I = np.random.randint(n)  # select one random element\n",
    "        gamma = 1/(k+1)\n",
    "        sum_gamma += gamma\n",
    "        sum_va += va0*gamma\n",
    "        va0 = va0-gamma*dev_f_i(va0,I)  # multiply by the random element selected\n",
    "    return sum_va/sum_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial value of f : 569.0\n",
      "Final value of f : 55244.8425308796\n"
     ]
    }
   ],
   "source": [
    "va0 = np.zeros((31,))\n",
    "print(\"Initial value of f :\",f(va0))\n",
    "va1 = stochastic_gradient(va0, 100000)\n",
    "print(\"Final value of f :\",f(va1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Augmented Lagrangian method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "The lagrangian problem of (1) is written : $L(v, a, \\xi, \\phi) = \\frac{1}{2} \\sum_jv_j^2 + c\\sum_i\\xi_i + \\sum_i\\phi_i \\times (1-M_i(v,a)-\\xi_i) + \\sum_i \\iota_{R_+}(\\phi_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f(x) = \\frac{\\rho}{2}(max(0,x))^2 $$\n",
    "$$ h(x, \\phi) = x+\\frac{\\phi}{\\rho} $$\n",
    "\n",
    "$$ \\nabla_x g(x,\\phi) = h_x'(x,\\phi) \\, f'( h(x,\\phi) ) $$\n",
    "\n",
    "$$ \\nabla_\\phi g(x,\\phi) = h_\\phi'(x,\\phi) \\, f'( h(x,\\phi) ) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "$ \\nabla_xg(x, \\phi) $ is an increasing function as $ \\forall x,y \\, \\nabla_xg(x, \\phi) - \\nabla_xg(x, \\phi) \\geq 0 $\n",
    "\n",
    "$ \\nabla_\\phi g(x, \\phi) $ is an decreasing function as $ \\forall \\phi1,\\phi2 \\, \\nabla_{\\phi1} g(x, \\phi1) - \\nabla_{\\phi2} g(x, \\phi2) \\geq 0 $\n",
    "\n",
    "So we have $x \\mapsto g(x,\\phi) \\ convex $ and $ \\phi\\mapsto g(x,\\phi) \\ concave $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rho = 2\n",
    "eps = 1\n",
    "\n",
    "def nabla_g_x(x, phi):\n",
    "    return rho * np.maximum(np.zeros(x.shape), x + phi/rho)\n",
    "\n",
    "def nabla_g_phi(x, phi):\n",
    "    return np.maximum(-phi/rho, x)\n",
    "\n",
    "def min_L(phi, psi, eps):\n",
    "    \"\"\"\n",
    "        seach of the Lagrangian minimum\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialization of the variables\n",
    "    v = np.zeros((30,))\n",
    "    a = 0\n",
    "    xi = np.zeros((569,))\n",
    "    \n",
    "    # initialization of the variatio nof the variables\n",
    "    dv = np.zeros((30,))\n",
    "    da = 1.5\n",
    "    dxi = np.zeros((569,))\n",
    "    \n",
    "    while (np.sum(dv**2)+da**2+np.sum(dxi**2)>1) > 1:\n",
    "        \n",
    "        x = 1-xi-np.dot(np.diag(y), np.dot(X, v) + a)\n",
    "\n",
    "        # implement graident of each variables\n",
    "        dv = v - np.transpose(np.dot(np.dot(np.diag(y), X)), nabla_g_x(x, psi))\n",
    "        da = -np.sum(y * nabla_g_x(x,psi))\n",
    "        dxi = c - nabla_g_x(-xi, phi) - nabla_g_x(x, psi)\n",
    "        \n",
    "        gamma = 1/100\n",
    "        v -= gamma * dv\n",
    "        a -= gamma * da\n",
    "        xi -= gamma * dxi \n",
    "        \n",
    "    return v, a, xi\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def nabla_phi_L(v,a,xi,phi,psi):\n",
    "    return nabla_phi_g(-xi, phi)\n",
    "\n",
    "def nabla_psi_L(v,a,xi,phi,psi):\n",
    "    x = 1-xi-np.dot(np.diag(y), np.dot(X, v) + a)\n",
    "    return nabla_phi_g(x, psi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
